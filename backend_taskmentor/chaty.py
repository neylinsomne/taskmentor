import os
import torch
import numpy as np
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from sklearn.preprocessing import LabelEncoder
import json


class ChatbotModel:
    def __init__(self, model_dir, intents_file, max_sequence_len=20, confidence_threshold=0.7):
        self.model_dir = model_dir
        self.max_sequence_len = max_sequence_len
        self.confidence_threshold = confidence_threshold

        # Cargar intents y etiquetas
        self.intents = self.load_intents(intents_file)
        self.label_encoder = self.init_label_encoder()

        # Cargar el modelo y el tokenizer
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model, self.tokenizer = self.load_model_and_tokenizer()
        self.model.to(self.device)
        self.model.eval()  # Para asegurarse de que est√° en modo evaluaci√≥n

        # Inicializar √∫ltima opci√≥n para evitar respuestas repetidas
        self.ultima_opcion = None

    def load_intents(self, intents_file):
        """Cargar el archivo de intents desde un archivo JSON."""
        with open(intents_file, "r", encoding="utf-8") as file:
            intents = json.load(file)
        return intents

    def init_label_encoder(self):
        """Inicializa el codificador de etiquetas a partir de los intents."""
        labels = [intent['tag'] for intent in self.intents['intents']]
        label_encoder = LabelEncoder()
        label_encoder.fit(labels)
        return label_encoder

    def load_model_and_tokenizer(self):
        """Carga el modelo y el tokenizer desde el directorio especificado."""
        model = AutoModelForSequenceClassification.from_pretrained(self.model_dir)
        tokenizer = AutoTokenizer.from_pretrained(self.model_dir + '/tokenizer')
        return model, tokenizer

    def preprocess_text(self, text):
        """Preprocesa el texto: convertir en min√∫sculas y eliminar espacios extras."""
        return text.lower().strip()

    def tokenize_input(self, user_input):
        """Tokeniza el input del usuario."""
        return self.tokenizer(
            user_input, return_tensors="pt", padding=True, truncation=True, max_length=self.max_sequence_len
        ).to(self.device)

    def predict_intent(self, user_input):
        """Predice el intent basado en el input del usuario."""
        input_text = self.preprocess_text(user_input)
        inputs = self.tokenize_input(input_text)

        # Realizar predicci√≥n
        with torch.no_grad():
            outputs = self.model(**inputs)

        # Obtener logits y calcular probabilidades con softmax
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=-1).cpu().numpy()

        # Obtener el √≠ndice con mayor probabilidad
        intent_index = np.argmax(probabilities)
        max_prob = probabilities[0][intent_index]

        return intent_index, max_prob

    def get_response(self, user_input):
        """Genera la respuesta del chatbot basada en la predicci√≥n."""

        # Predecir el intent
        intent_index, max_prob = self.predict_intent(user_input)

        # Si la confianza es baja, pedir aclaraci√≥n o sugerir una reformulaci√≥n
        if max_prob < self.confidence_threshold:
            return "Lo siento, no estoy seguro de c√≥mo responder a eso. ¬øPodr√≠as intentar reformular tu pregunta?"

        # Obtener el intent predicho (tag)
        intent_tag = self.label_encoder.inverse_transform([intent_index])[0]
        print(f"Intento predicho: {intent_tag}, con probabilidad: {max_prob}")

        # Evitar respuestas repetidas
        if self.ultima_opcion == intent_tag:
            return "Parece que ya te respond√≠ algo similar. ¬øTe gustar√≠a saber m√°s sobre otro tema?"

        # Guardar el √∫ltimo intent para evitar repetici√≥n de respuestas
        self.ultima_opcion = intent_tag

        # L√≥gica para manejar respuestas espec√≠ficas por intent y palabras clave
        return self.generate_response_by_intent(intent_tag, user_input)

    def generate_response_by_intent(self, intent_tag, user_input):
        """Genera respuestas basadas en el intent y las palabras clave en el input."""

        # Convertir la entrada a min√∫sculas para facilitar la b√∫squeda de palabras clave
        user_input_lower = user_input.lower()

        if intent_tag == "ciencias":
            return self.handle_science_questions(user_input_lower)

        elif intent_tag == "fisica":
            return self.handle_physics_questions(user_input_lower)

        elif intent_tag == "historia":
            return self.handle_history_questions(user_input_lower)

        # Si no se detecta ning√∫n intent, responder con un mensaje gen√©rico
        return "Lo siento, no entend√≠ tu mensaje. ¬øPodr√≠as intentar preguntar de otra manera?"

    def handle_science_questions(self, user_input):
        """Manejo de respuestas espec√≠ficas para preguntas de ciencias."""
        if "adn" in user_input:
            return "El ADN, o √°cido desoxirribonucleico, es la mol√©cula que contiene las instrucciones gen√©ticas."
        elif "evoluci√≥n" in user_input:
            return "La evoluci√≥n es el proceso por el cual las especies cambian con el tiempo a trav√©s de la selecci√≥n natural."
        elif "ecosistema" in user_input:
            return "Un ecosistema es una comunidad de organismos vivos que interact√∫an entre s√≠ y con su entorno, como el suelo y el agua."
        elif "dame un dato" in user_input:
            return "La fotos√≠ntesis es el proceso por el cual las plantas convierten la luz solar en energ√≠a qu√≠mica, produciendo ox√≠geno."
        else:
            return "Las ciencias abarcan muchos temas, ¬øpodr√≠as especificar de qu√© √°rea te gustar√≠a saber m√°s?"

    def handle_physics_questions(self, user_input):
        """Manejo de respuestas espec√≠ficas para preguntas de f√≠sica."""
        if "newton" in user_input:
            return "Las leyes de Newton son tres principios fundamentales que describen el movimiento de los cuerpos."
        elif "gravedad" in user_input:
            return "La ley de la gravedad de Newton establece que todos los cuerpos se atraen mutuamente con una fuerza que es proporcional a sus masas."
        elif "energ√≠a" in user_input:
            return "En f√≠sica, la energ√≠a se define como la capacidad de realizar un trabajo. Existen diferentes formas de energ√≠a como la cin√©tica y la potencial."
        elif "dame un dato" in user_input:
            return "La teor√≠a de la relatividad de Einstein revolucion√≥ nuestra comprensi√≥n del espacio y el tiempo."
        else:
            return "La f√≠sica es fascinante. ¬øTe gustar√≠a aprender sobre mec√°nica cu√°ntica, relatividad, o algo m√°s espec√≠fico?"

    def handle_history_questions(self, user_input):
        """Manejo de respuestas espec√≠ficas para preguntas de historia."""
        if "col√≥n" in user_input or "descubrimiento" in user_input:
            return "Crist√≥bal Col√≥n lleg√≥ a Am√©rica en 1492, marcando un punto clave en la historia mundial."
        elif "revoluci√≥n" in user_input:
            return "La Revoluci√≥n Francesa fue un evento crucial que marc√≥ el fin de la monarqu√≠a en Francia y el inicio de una nueva era pol√≠tica."
        elif "dame un dato" in user_input:
            return "El Imperio Romano fue uno de los imperios m√°s grandes y poderosos de la historia, que dur√≥ m√°s de mil a√±os."
        else:
            return "La historia es vasta y rica. ¬øSobre qu√© evento o personaje hist√≥rico te gustar√≠a aprender m√°s?"


# Funci√≥n principal para interactuar con el chatbot
def main():
    model_dir = "modelo"  # Ruta completa donde est√° guardado el modelo
    intents_file = "intents_10000_no_accents.json"  # Archivo JSON con los intents

    # Inicializar el modelo del chatbot
    chatbot = ChatbotModel(model_dir, intents_file)

    print("¬°Hola! Soy tu asistente virtual. ¬øEn qu√© puedo ayudarte hoy?")

    while True:
        user_input = input("T√∫: ")

        # Verificar si el usuario quiere salir
        if user_input.lower() in ["salir", "exit", "quit"]:
            print("¬°Hasta luego! üòä")
            break

        # Obtener la respuesta del chatbot
        response = chatbot.get_response(user_input)
        print(f"Chatbot: {response}")


if __name__ == "__main__":
    main()
